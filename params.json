{
  "name": "Neuralnetworkwithlasagne",
  "tagline": "CNN and two layer NN comparision with Theano and Lasagne to do handwritten digit recognition.",
  "body": "#Neural Network with Theono and Lasagne on MNIST data\r\n\r\n####Sample Digits\r\n![Sample digits](digits.png)\r\n##Convolutional Neural Network model\r\nInput Layer: 28 x 28  \r\nConvLayer 1: 32 x 5 x 5  \r\nConvLayer 2: 32 x 5 x 5  \r\nDenseLayer 1: 256   \r\nDenseLayer 2: 256 * 10  \r\n\r\n####Using mini-batch: epoch - 30, test accuracy 99.15%\r\nEach epoch took around 60-90 seconds. The training and validation loss is shown below\r\n<img src=\"loss_cnn.png\" alt=\"alt text\" width=\"350\" height=\"250\">\r\n\r\n\r\n##2 Layer Neural Network Model\r\nInput Layer size: 784 with 20% drop-out and ReLU activation   \r\nHidden Layer size: 784 x 625 with 50% drop-out with ReLU activation  \r\nOutput Layer: 625 x 10 with 50% drop-out with softmax activation  \r\n\r\n####Without using mini-batch: epoch - 500, test accuracy 93%\r\nTried to train a simple 2 layer network with no minibatch. Got around 93% test accuracy after 500 epochs. The training and validation loss is shown below      \r\n \r\n \r\n<img src=\"loss_no_mb.png\" alt=\"alt text\" width=\"350\" height=\"250\">\r\n\r\n\r\n####Using mini-batch: epoch - 150, test accuracy 98.15%\r\nUsing mini-batch the learning is faster. Each epoch took around 6 seconds. The training and validation loss is shown below\r\n\r\n\r\n<img src=\"loss_mb.png\" alt=\"alt text\" width=\"350\" height=\"250\">\r\n\r\n\r\n\r\n\r\n\r\n",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}